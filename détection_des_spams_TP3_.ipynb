{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "détection des spams TP3 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYvaJpOSI0bEbe7dCux2+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/groupe11ML/groupe11ML/blob/main/d%C3%A9tection_des_spams_TP3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GROUPE 11 \n",
        "#KEUFACK DONGMO BELVIANE BERENICE 19Y204\n",
        "#LEUKAM FERMAT 19Y208\n",
        "#LONTSI TIDOH MOREL 19Y082\n",
        "#TCHAMEDEU TCHAMEDEU JORDAN STEVE 19Y458"
      ],
      "metadata": {
        "id": "Um9OU3CbnquI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le cadre de la classification des emails (spam ou ham), les caractéristiques à comparer sont les fréquences d'un mot dans chaque email. La distance euclidienne est utilisée pour déterminer la similarité entre deux e-mails ; plus la distance est petite, plus elle est similaire. "
      ],
      "metadata": {
        "id": "SQQwz_M2qpKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROCEDURE :\n",
        "1. Chargez les e-mails de spam et de jambon\n",
        "2. Supprimer la ponctuation et les symboles courants\n",
        "3. Minuscule toutes les lettres\n",
        "4. Supprimez les mots vides (mots très courants comme les pronoms, les articles, etc.)\n",
        "5. Divisez les e-mails en e-mails de formation et en e-mails de test\n",
        "6. Pour chaque e-mail de test, calculez la similarité entre celui-ci et tous les e-mails de formation\n",
        "    6.1. Pour chaque mot qui existe dans l'e-mail de test ou l'e-mail de formation, comptez sa fréquence dans les deux e-mails\n",
        "    6.2. calculer la distance euclidienne entre les deux e-mails pour déterminer la similarité\n",
        "7. Trier les e-mails par ordre croissant de distance euclidienne\n",
        "8. Sélectionnez les k voisins les plus proches (distance la plus courte)\n",
        "9. Attribuez la classe la plus fréquente dans les k plus proches voisins sélectionnés au nouvel e-mail"
      ],
      "metadata": {
        "id": "b0h30RTsHlRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliothèques utilisées :"
      ],
      "metadata": {
        "id": "AF7SpNI9H5c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Gsi_pMLBnxMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bibliothèque os pour ouvrir et lire des fichiers.\n",
        "bibliothèque string pour la liste de ponctuation\n",
        "stopwords contient la liste des mots vides.\n",
        "train_test_split pour diviser les données en données d'apprentissage et de test.\n",
        "accuracy_score pour calculer la précision des algorithmes.\n",
        "numpy pour permettre une manipulation avancée des tableaux."
      ],
      "metadata": {
        "id": "WMtUzjK-rJU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Data"
      ],
      "metadata": {
        "id": "pbspA86asNQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    print(\"Loading data...\")\n",
        "    \n",
        "    ham_files_location = os.listdir(\"dataset/ham\")\n",
        "    spam_files_location = os.listdir(\"dataset/spam\")\n",
        "    data = []\n",
        "    # Load ham email\n",
        "    for file_path in ham_files_location:\n",
        "    f = open(\"dataset/ham/\" + file_path, \"r\")\n",
        "    text = str(f.read())\n",
        "    data.append([text, \"ham\"])\n",
        "      \n",
        "  # Load spam email\n",
        "    for file_path in spam_files_location:\n",
        "    f = open(\"dataset/spam/\" + file_path, \"r\")\n",
        "    text = str(f.read())\n",
        "    data.append([text, \"spam\"])\n",
        "    data = np.array(data) \n",
        "    \n",
        "    print(\"drapeau 1 : données chargées\") \n",
        "    return data"
      ],
      "metadata": {
        "id": "B6JoTbXGsOHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "os.listdir() renvoie une liste de tous les noms de fichiers à l'intérieur d'un dossier. Ceci est utilisé pour récupérer tous les noms de fichiers des fichiers texte dans chacun des dossiers ham et spam et les stocker respectivement dans ham_files_location et spam_files_location. data est une liste pour stocker chaque texte d'e-mail et son étiquette correspondante.\n"
      ],
      "metadata": {
        "id": "s4llvKhZscQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les données de la liste sont transformées en un tableau numpy, pour permettre une meilleure manipulation du tableau ultérieurement. les données sont ensuite renvoyées."
      ],
      "metadata": {
        "id": "8RhObTkaOuUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prétraitement des données"
      ],
      "metadata": {
        "id": "rhgju2JLO2wL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "punc contient une liste de ponctuation et de symboles\n",
        "sw contient une liste de mots vides de la bibliothèque nltk.corpus"
      ],
      "metadata": {
        "id": "R3oT0T7lw8m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour chaque enregistrement dans data, pour chaque élément (symbole ou ponctuation) dans punct, remplacez l'élément par une chaîne vide, pour supprimer l'élément de record[0] (chaîne de texte d'e-mail)."
      ],
      "metadata": {
        "id": "b9ZwrTbhw-rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RcQ4Ltvzyr-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data: noise removal\n",
        "def preprocess_data(data):\n",
        "    print(\"Preprocessing data...\")\n",
        "    \n",
        "    punc = string.punctuation           # Punctuation list\n",
        "    sw = stopwords.words('english')     # Stopwords list\n",
        "    for record in data:\n",
        "        # Remove common punctuation and symbols\n",
        "        for item in punc:\n",
        "            record[0] = record[0].replace(item, \"\")\n",
        "        # Lowercase all letters and remove stopwords \n",
        "        splittedWords = record[0].split()\n",
        "        newText = \"\"\n",
        "        for word in splittedWords:\n",
        "            if word not in sw:\n",
        "                word = word.lower()\n",
        "                newText = newText + \" \" + word  \n",
        "        record[0] = newText\n",
        "        \n",
        "    print(\"flag 2: preprocessed data\")        \n",
        "    return data"
      ],
      "metadata": {
        "id": "zkZQaSGbO8Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez la méthode split () sur l'enregistrement de texte de l'e-mail [0] pour renvoyer une liste de tous les mots de l'e-mail. Parcourez cette liste de mots, et si le mot n'est pas dans la liste des mots vides, mettez-le en minuscules et ajoutez le mot à newText. newText contiendra l'e-mail mais vide de mots vides. newText est réattribué à record[0]. Une fois que chaque enregistrement[0] a été prétraité, les données nettoyées sont renvoyées."
      ],
      "metadata": {
        "id": "28MY5kQ1yvt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PthkB7mYsLQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f0b671-913b-4d57-c1a4-daf775e1b733"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fractionnement des données en ensembles d'apprentissage et de test\n",
        "L'ensemble de données est divisé en un ensemble d'apprentissage (73 %) et un ensemble de test (27 %)."
      ],
      "metadata": {
        "id": "PoGgcyTfzDb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting original dataset into training dataset and test dataset\n",
        "def split_data(data):\n",
        "    print(\"Splitting data...\")\n",
        "    \n",
        "    features = data[:, 0]   # array containing all email text bodies\n",
        "    labels = data[:, 1]     # array containing corresponding labels\n",
        "    print(labels)\n",
        "    training_data, test_data, training_labels, test_labels =train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
        "    \n",
        "    print(\"flag 3: splitted data\")\n",
        "    return training_data, test_data, training_labels, test_labels"
      ],
      "metadata": {
        "id": "yWkZaczOzSp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout d'abord, il était nécessaire d'avoir les textes des e-mails dans un tableau qui leur était propre et les étiquettes dans un autre tableau qui leur était propre. Ainsi, les textes des e-mails étaient stockés dans des fonctionnalités et les étiquettes étaient stockées dans des étiquettes. La méthode train_test_split a ensuite été utilisée pour diviser les données en training_data, test_data, training_labels et test_labels. L'état aléatoire a été défini sur 42 pour garantir que la même sortie de mélange aléatoire sera obtenue à des fins de test. Après le fractionnement, training_data, test_data, training_labels et test_labels sont renvoyés."
      ],
      "metadata": {
        "id": "B_K-goKz0AFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The KNN Algorithm"
      ],
      "metadata": {
        "id": "df07nem7PpIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fonction get_count()"
      ],
      "metadata": {
        "id": "hzn468mu0YM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(text):\n",
        "    wordCounts = dict()\n",
        "    for word in text.split():\n",
        "        if word in wordCounts:\n",
        "            wordCounts[word] += 1\n",
        "        else:\n",
        "            wordCounts[word] = 1\n",
        "    \n",
        "    return wordCounts"
      ],
      "metadata": {
        "id": "fHlkzgrN0hWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction prend un seul texte d'e-mail et le divise à l'aide de split(). La fréquence d'occurrence de chaque mot dans l'e-mail est comptée et enregistrée dans wordCounts, qui est de type dictionnaire. Le dictionnaire wordCounts est ensuite renvoyé."
      ],
      "metadata": {
        "id": "sibYJckz0i8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "euclidean_difference() function"
      ],
      "metadata": {
        "id": "G31hjpCb02Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sa fonction prend en compte un dictionnaire de nombre de mots d'un e-mail de test test_WordCounts, et un autre dictionnaire d'un e-mail de formation, training_wordCounts. total stocke la somme de la différence au carré de la fréquence d'un mot dans l'e-mail de test et d'entraînement."
      ],
      "metadata": {
        "id": "SppZYxZD3Pvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
        "    total = 0\n",
        "    for word in test_WordCounts:\n",
        "        if word in test_WordCounts and word in training_WordCounts:\n",
        "            total += (test_WordCounts[word] - training_WordCounts[word])**2\n",
        "            del training_WordCounts[word]\n",
        "        else:\n",
        "            total += test_WordCounts[word]**2\n",
        "    for word in training_WordCounts:\n",
        "            total += training_WordCounts[word]**2\n",
        "    return total**0.5"
      ],
      "metadata": {
        "id": "wlSBYcrb09A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout d'abord, nous parcourons les mots du dictionnaire d'e-mails de test. Pour chaque mot, il y a trois cas. Le premier cas est qu'il existe à la fois dans l'e-mail de test et dans l'e-mail de formation. Dans ce cas, le total est incrémenté de la différence au carré de la fréquence du mot dans l'e-mail de test et l'e-mail de formation."
      ],
      "metadata": {
        "id": "9nCt5sS53RLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuite, le mot commun est supprimé du dictionnaire des e-mails de formation, pour accélérer la prochaine boucle for"
      ],
      "metadata": {
        "id": "JxcTstAp3aqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le deuxième cas est que le mot est uniquement dans l'e-mail de test. Dans ce cas, il n'est pas nécessaire de trouver la différence (puisque sa fréquence est de 0 dans l'e-mail de formation), nous ajoutons donc simplement la fréquence au carré du mot au total."
      ],
      "metadata": {
        "id": "n768Tb0u3kdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dernier cas est que le mot est uniquement dans l'e-mail de formation. Étant donné que nous avons supprimé tous les mots courants dans la boucle for précédente, nous parcourons simplement le dictionnaire des e-mails de formation et ajoutons la fréquence au carré de chaque mot au total."
      ],
      "metadata": {
        "id": "oRagUyzb3sjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, la racine carrée du total (la racine carrée de la somme de la différence au carré des fréquences de chaque mot) est renvoyée sous la forme d'un double. C'est la fin de la fonction de calcul de la distance euclidienne."
      ],
      "metadata": {
        "id": "Zpn3nm5x31sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_class() function"
      ],
      "metadata": {
        "id": "EPg2iuen4FKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction prend en compte la liste des K plus proches voisins sélectionnés pour déterminer la classe de l'email de test en cours. spam_count et ham_count stockent la fréquence d'occurrence de chaque étiquette \"spam\" et étiquette \"ham\" respectivement dans les K voisins les plus proches sélectionnés."
      ],
      "metadata": {
        "id": "8xNwWwre5JP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(selected_Kvalues):\n",
        "    spam_count = 0\n",
        "    ham_count = 0\n",
        "    for value in selected_Kvalues:\n",
        "        if value[0] == \"spam\":\n",
        "            spam_count += 1\n",
        "        else:\n",
        "            ham_count += 1\n",
        "        if spam_count > ham_count:\n",
        "          return \"spam\"\n",
        "        else:\n",
        "          return \"ham\""
      ],
      "metadata": {
        "id": "cICAvH8P4LEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En utilisant une boucle for, pour chaque valeur parmi les K valeurs sélectionnées, si la valeur de l'étiquette [0] est égale à \"spam\", alors spam_count est incrémenté de 1. Sinon, ham_count est incrémenté de 1"
      ],
      "metadata": {
        "id": "y8S7QnNe5fOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après la boucle, si spam_count est supérieur à ham_count, cela signifie que l'e-mail de test actuel a plus tendance à être du spam, donc une chaîne \"spam\" est renvoyée comme étiquette prédite. Sinon, la chaîne \"ham\" est renvoyée comme étiquette prédite."
      ],
      "metadata": {
        "id": "dXVDTKCe6HWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#knn_classifier() function"
      ],
      "metadata": {
        "id": "lh8wbjAi4HAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est la fonction de classificateur KNN. Il prend en compte l'e-mail de formation, les étiquettes de formation, les données de test, la valeur K et le nombre d'e-mails de test à tester sur les 27 % d'e-mails de test d'origine. result est la liste qui contiendrait les étiquettes prédites. compteur sera simplement utilisé à des fins d'affichage pour indiquer la progression lorsque le programme est exécuté."
      ],
      "metadata": {
        "id": "Sl3Pj4k06b3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
        "    print(\"Running KNN Classifier...\")\n",
        "    \n",
        "    result = []\n",
        "    counter = 1\n",
        "    # word counts for training email\n",
        "    training_WordCounts = [] \n",
        "    for training_text in training_data:\n",
        "            training_WordCounts.append(get_count(training_text))\n",
        "    for test_text in test_data:\n",
        "        similarity = [] # List of euclidean distances\n",
        "        test_WordCounts = get_count(test_text)  # word counts for test email\n",
        "        # Getting euclidean difference \n",
        "        for index in range(len(training_data)):\n",
        "            euclidean_diff =euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
        "            similarity.append([training_labels[index], euclidean_diff])\n",
        "        # Sort list in ascending order based on euclidean difference\n",
        "        similarity = sorted(similarity, key = lambda i:i[1])\n",
        "        # Select K nearest neighbours\n",
        "        selected_Kvalues = [] \n",
        "        for i in range(K):\n",
        "            selected_Kvalues.append(similarity[i])\n",
        "        # Predicting the class of email\n",
        "        result.append(get_class(selected_Kvalues))\n",
        "        return result"
      ],
      "metadata": {
        "id": "4KI4CD9b6kN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étant donné que l'ensemble de formation est constant, nous pouvons compter une fois pour toutes la fréquence des mots dans chaque e-mail de formation. Ainsi, pour chaque texte d'e-mail dans les données d'apprentissage, son dictionnaire de fréquence de mots est obtenu à l'aide de get_count(). Le dictionnaire est ensuite ajouté à la liste training_WordCounts pour être stocké.\n"
      ],
      "metadata": {
        "id": "Go0KPndN71x2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Désormais, pour chaque e-mail de test dans les données de test, les opérations suivantes sont effectuées. Une similarité de liste vide est déclarée. Il stockera les distances euclidiennes entre l'e-mail de test actuel et chaque e-mail d'entraînement. Ensuite, le dictionnaire de fréquence des mots de l'e-mail de test est obtenu à l'aide de get_count()."
      ],
      "metadata": {
        "id": "ITwJk1Gp8Koa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puisque nous avons déjà les dictionnaires de fréquence des mots de tous les e-mails de formation et l'e-mail de test actuel. Nous pouvons continuer à calculer la distance euclidienne entre l'e-mail de test actuel et chaque e-mail d'entraînement à l'aide d'une boucle for qui itère x fois, où x est égal à la taille de l'ensemble de données d'entraînement. Après chaque itération, la distance euclidienne calculée est ajoutée à la liste de similarité, ainsi que l'étiquette correspondante de l'e-mail d'entraînement."
      ],
      "metadata": {
        "id": "NkNc3Hpe8TUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après que toutes les distances euclidiennes ont été stockées. Nous trions la liste de similarité par ordre croissant en fonction de la deuxième colonne, c'est-à-dire en fonction de la distance euclidienne (du plus proche au plus éloigné)."
      ],
      "metadata": {
        "id": "hSD9myhS8ZcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, puisque la liste de similarité est déjà triée, nous pouvons facilement ajouter les K voisins les plus proches à la liste selected_Kvalues ​​en utilisant une simple boucle for."
      ],
      "metadata": {
        "id": "ixpmdS3q8aY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, et avant de passer au prochain e-mail de test. Nous déterminons la classe de l'e-mail de test actuel à l'aide de get_class(). Maintenant, nous avons atteint la fin d'une itération, et la prochaine itération peut commencer à classer le prochain e-mail de test."
      ],
      "metadata": {
        "id": "Rht7wiQl8x5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois que tous les e-mails de test ont été classés et que la boucle for a atteint sa fin, la liste des résultats, qui contient la liste des étiquettes prédites, est renvoyée."
      ],
      "metadata": {
        "id": "t5ZrcB0I86RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#main() function"
      ],
      "metadata": {
        "id": "euulGgpw89Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(K):\n",
        "    data = load_data()\n",
        "    data = preprocess_data(data)\n",
        "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "    tsize = len(test_data)\n",
        "    result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize) \n",
        "    accuracy = accuracy_score(test_labels[:tsize], result)\n",
        "    print(\"training data size\\t: \" + str(len(training_data)))\n",
        "    print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
        "    print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
        "    print(\"Samples tested\\t\\t: \" + str(tsize))\n",
        "    print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
        "    print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
        "    print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) * tsize)))\n",
        "main(11)"
      ],
      "metadata": {
        "id": "hbRELp049JE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "size spécifie le nombre d'e-mails de test (sur les 27 % de données de test d'origine) pour prédire leurs étiquettes. Actuellement, tsize est défini pour être égal à l'ensemble des e-mails de test."
      ],
      "metadata": {
        "id": "jOt-tvnt9O3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, la fonction knn_classifier() est appelée pour prédire les étiquettes des e-mails de test. La liste renvoyée des étiquettes prédites est stockée dans le résultat. Après cela, la précision est calculée à l'aide de la méthode precision_score() de la bibliothèque sklearn. Cette méthode compare la liste d'étiquettes réelle test_labels avec le résultat de la liste d'étiquettes prédite."
      ],
      "metadata": {
        "id": "geW3-m6a-kB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ces lignes affichent les détails de l'exécution tels que la taille des données de formation, la taille des données de test, la valeur K, le nombre d'échantillons testés, le pourcentage de précision, le nombre d'e-mails correctement identifiés et le nombre d'e-mails faussement identifiés."
      ],
      "metadata": {
        "id": "BGvCu53r-pgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "finalement, c'est la ligne qui initie le programme en appelant la fonction main, et lui donne la valeur K (qui est 11 dans ce cas)."
      ],
      "metadata": {
        "id": "IGZ_PH8N-y4s"
      }
    }
  ]
}